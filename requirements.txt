# Core dependencies
datasets>=2.14.0
transformers>=4.35.0
accelerate>=0.24.0
torch>=2.0.0
tqdm>=4.65.0
neo4j>=5.12.0

# For Qwen2.5 model optimization
einops>=0.7.0
tiktoken>=0.5.0
transformers_stream_generator>=0.0.4

# Optional: Flash Attention 2 for faster inference
# flash-attn>=2.3.0

# Quantization support
bitsandbytes>=0.41.0  # For 8-bit/4-bit quantization

sentence-transformers>=2.2.0  # For vector embeddings
numpy>=1.24.0
pandas>=2.0.0

pytest>=7.4.0
